# OpenAIé›†æˆä½¿ç”¨æŒ‡å—

## ğŸ“‹ æ¦‚è¿°

æœ¬ç³»ç»Ÿå·²é›†æˆOpenAI APIï¼Œå®ç°äº†æ™ºèƒ½é¢è¯•é—®é¢˜ç”Ÿæˆå’Œå€™é€‰äººå›ç­”è¯„ä¼°åŠŸèƒ½ã€‚

## ğŸ”‘ é…ç½®

### 1. è®¾ç½®OpenAI API Key

åœ¨è¿è¡Œåº”ç”¨ä¹‹å‰ï¼Œéœ€è¦è®¾ç½®ç¯å¢ƒå˜é‡ï¼š

```bash
export OPENAI_API_KEY="your-api-key-here"
```

æˆ–è€…åœ¨IDEAä¸­é…ç½®ç¯å¢ƒå˜é‡ï¼š
- Run -> Edit Configurations
- Environment variables: `OPENAI_API_KEY=your-api-key-here`

### 2. é…ç½®å‚æ•°

åœ¨ `application.properties` ä¸­å¯ä»¥è°ƒæ•´ä»¥ä¸‹å‚æ•°ï¼š

```properties
# OpenAIæ¨¡å‹é…ç½®
openai.model=gpt-3.5-turbo          # ä½¿ç”¨çš„æ¨¡å‹
openai.temperature=0.7               # ç”Ÿæˆæ¸©åº¦ (0-1)
openai.max-tokens=1000              # æœ€å¤§tokenæ•°
openai.max-history-messages=10      # ä¿ç•™çš„å†å²å¯¹è¯è½®æ•°
```

## ğŸ¯ æ ¸å¿ƒåŠŸèƒ½

### 1. æ™ºèƒ½é—®é¢˜ç”Ÿæˆ

**Endpoint:** `POST /api/llm/question-generate`

æ ¹æ®å²—ä½ã€å€™é€‰äººèƒŒæ™¯å’Œå¯¹è¯å†å²ï¼Œæ™ºèƒ½ç”Ÿæˆä¸‹ä¸€ä¸ªé¢è¯•é—®é¢˜ã€‚

**è¯·æ±‚ç¤ºä¾‹ï¼š**
```json
{
  "sessionId": "session-uuid",
  "roleId": "backend_java",
  "level": "mid",
  "candidateInfo": {
    "workExperience": [...],
    "projects": [...]
  }
}
```

**å“åº”ç¤ºä¾‹ï¼š**
```json
{
  "question": "æˆ‘çœ‹åˆ°ä½ åœ¨ç®€å†ä¸­æåˆ°äº†å¾®æœåŠ¡æ¶æ„çš„ç»éªŒ...",
  "sessionId": "session-uuid",
  "questionNumber": 3
}
```

### 2. æµå¼é—®é¢˜ç”Ÿæˆï¼ˆSSEï¼‰

**Endpoint:** `GET /api/llm/question-generate/stream`

å®æ—¶æµå¼è¾“å‡ºé—®é¢˜ï¼Œæä¾›æ›´å¥½çš„ç”¨æˆ·ä½“éªŒã€‚

**è¯·æ±‚ç¤ºä¾‹ï¼š**
```bash
curl -N "http://localhost:8080/api/llm/question-generate/stream?sessionId=xxx&roleId=backend_java&level=mid"
```

**å“åº”æ ¼å¼ï¼š**
```
data: æˆ‘
data: çœ‹åˆ°
data: ä½ åœ¨
data: ç®€å†ä¸­
...
event: end
data: [DONE]
```

### 3. å›ç­”è¯„ä¼°

**Endpoint:** `POST /api/llm/eval`

è¯„ä¼°å€™é€‰äººçš„å›ç­”è´¨é‡ï¼Œæä¾›è¯¦ç»†çš„è¯„åˆ†å’Œæ”¹è¿›å»ºè®®ã€‚

**è¯·æ±‚ç¤ºä¾‹ï¼š**
```json
{
  "question": "è¯·è§£é‡ŠHashMapçš„å·¥ä½œåŸç†",
  "answer": "HashMapåŸºäºå“ˆå¸Œè¡¨å®ç°...",
  "roleId": "backend_java",
  "level": "mid"
}
```

**å“åº”ç¤ºä¾‹ï¼š**
```json
{
  "score": 85.0,
  "rubricLevel": "good",
  "detailedScores": {
    "technicalAccuracy": 9,
    "depth": 8,
    "experience": 8,
    "communication": 9
  },
  "strengths": [
    "å‡†ç¡®ç†è§£äº†HashMapçš„åº•å±‚å®ç°",
    "æ¸…æ™°è§£é‡Šäº†å“ˆå¸Œå†²çªçš„å¤„ç†æ–¹å¼"
  ],
  "improvements": [
    "å¯ä»¥æ·±å…¥è®¨è®ºæ‰©å®¹æœºåˆ¶çš„ç»†èŠ‚",
    "å»ºè®®è¡¥å……å¹¶å‘åœºæ™¯ä¸‹çš„é—®é¢˜"
  ],
  "followUpQuestions": [
    "HashMapåœ¨é«˜å¹¶å‘æƒ…å†µä¸‹ä¼šæœ‰ä»€ä¹ˆé—®é¢˜ï¼Ÿ",
    "ConcurrentHashMapæ˜¯å¦‚ä½•è§£å†³è¿™äº›é—®é¢˜çš„ï¼Ÿ"
  ]
}
```

### 4. é€šç”¨å¯¹è¯

**Endpoint:** `POST /api/llm/chat`

ç”¨äºè‡ªå®šä¹‰å¯¹è¯åœºæ™¯ã€‚

**è¯·æ±‚ç¤ºä¾‹ï¼š**
```json
{
  "messages": [
    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæŠ€æœ¯é¢è¯•å®˜"},
    {"role": "user", "content": "è¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±"}
  ]
}
```

### 5. å¥åº·æ£€æŸ¥

**Endpoint:** `GET /api/llm/health`

æ£€æŸ¥OpenAIæœåŠ¡é…ç½®çŠ¶æ€ã€‚

**å“åº”ç¤ºä¾‹ï¼š**
```json
{
  "configured": true,
  "status": "ready",
  "message": "OpenAI service is ready"
}
```

## ğŸ“ Promptç®¡ç†

ç³»ç»Ÿä½¿ç”¨JSONæ–‡ä»¶ç®¡ç†promptæ¨¡æ¿ï¼Œä¾¿äºç»´æŠ¤å’Œè¿­ä»£ã€‚

### Promptæ–‡ä»¶ä½ç½®

- `src/main/resources/prompts/system-prompts.json` - ç³»ç»Ÿçº§prompt
- `src/main/resources/prompts/role-prompts.json` - å²—ä½ç‰¹å®šprompt

### è‡ªå®šä¹‰Prompt

#### 1. ä¿®æ”¹ç³»ç»ŸåŸºç¡€Prompt

ç¼–è¾‘ `system-prompts.json`ï¼š

```json
{
  "base": "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æŠ€æœ¯é¢è¯•å®˜...",
  "evaluation": "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æŠ€æœ¯é¢è¯•è¯„ä¼°ä¸“å®¶..."
}
```

#### 2. æ·»åŠ æ–°çš„å²—ä½ç±»å‹

ç¼–è¾‘ `role-prompts.json`ï¼š

```json
{
  "roles": {
    "your_new_role": {
      "name": "å²—ä½åç§°",
      "description": "å²—ä½æè¿°",
      "focus_areas": ["æŠ€èƒ½1", "æŠ€èƒ½2"],
      "levels": {
        "junior": {...},
        "mid": {...},
        "senior": {...}
      }
    }
  }
}
```

## ğŸ”„ å·¥ä½œæµç¨‹

### å®Œæ•´é¢è¯•æµç¨‹

1. **åˆ›å»ºä¼šè¯**
```bash
POST /api/sessions
{
  "roleId": "backend_java",
  "level": "mid",
  "skills": ["java_core", "spring_boot"]
}
```

2. **ç”Ÿæˆç¬¬ä¸€ä¸ªé—®é¢˜**
```bash
POST /api/llm/question-generate
{
  "sessionId": "...",
  "roleId": "backend_java",
  "level": "mid"
}
```

3. **å€™é€‰äººå›ç­”**
```bash
POST /api/sessions/{sessionId}/answer
{
  "questionId": "...",
  "questionText": "...",
  "answerText": "å€™é€‰äººçš„å›ç­”"
}
```

4. **è¯„ä¼°å›ç­”**
```bash
POST /api/llm/eval
{
  "question": "...",
  "answer": "...",
  "roleId": "backend_java",
  "level": "mid"
}
```

5. **ç”Ÿæˆä¸‹ä¸€ä¸ªé—®é¢˜**ï¼ˆé‡å¤æ­¥éª¤2-4ï¼‰

6. **ç”Ÿæˆæœ€ç»ˆåé¦ˆ**
```bash
POST /api/sessions/{sessionId}/feedback
```

## ğŸ¨ å‰ç«¯é›†æˆç¤ºä¾‹

### ä½¿ç”¨æµå¼è¾“å‡º

```javascript
const eventSource = new EventSource(
  `http://localhost:8080/api/llm/question-generate/stream?sessionId=${sessionId}&roleId=${roleId}&level=${level}`
);

let question = "";

eventSource.onmessage = (event) => {
  if (event.data === "[DONE]") {
    eventSource.close();
    console.log("å®Œæ•´é—®é¢˜:", question);
  } else {
    question += event.data;
    updateUI(question); // å®æ—¶æ›´æ–°UI
  }
};

eventSource.onerror = (error) => {
  console.error("Stream error:", error);
  eventSource.close();
};
```

### ä½¿ç”¨éæµå¼è¾“å‡º

```javascript
const response = await fetch("http://localhost:8080/api/llm/question-generate", {
  method: "POST",
  headers: { "Content-Type": "application/json" },
  body: JSON.stringify({
    sessionId: sessionId,
    roleId: "backend_java",
    level: "mid"
  })
});

const data = await response.json();
console.log("é—®é¢˜:", data.question);
```

## âš¡ æ€§èƒ½ä¼˜åŒ–

### Tokenç®¡ç†

ç³»ç»Ÿè‡ªåŠ¨ç®¡ç†å¯¹è¯å†å²ï¼Œåªä¿ç•™æœ€è¿‘Nè½®å¯¹è¯ï¼ˆé»˜è®¤10è½®ï¼‰ï¼Œä»¥æ§åˆ¶tokenä½¿ç”¨ã€‚

### ç¼“å­˜ç­–ç•¥

å¯¹äºç›¸åŒçš„é—®é¢˜ç”Ÿæˆè¯·æ±‚ï¼Œå»ºè®®åœ¨åº”ç”¨å±‚å®ç°ç¼“å­˜ï¼š

```java
// å¯ä»¥åŸºäº roleId + level + history ç”Ÿæˆç¼“å­˜key
String cacheKey = String.format("%s:%s:%d", roleId, level, historySize);
```

### é”™è¯¯å¤„ç†

æ‰€æœ‰APIè°ƒç”¨éƒ½åŒ…å«fallbackæœºåˆ¶ï¼š
- OpenAIæœåŠ¡ä¸å¯ç”¨æ—¶ï¼Œè¿”å›å‹å¥½çš„é”™è¯¯æ¶ˆæ¯
- è¯„ä¼°å¤±è´¥æ—¶ï¼Œä½¿ç”¨åŸºäºè§„åˆ™çš„ç®€å•è¯„åˆ†

## ğŸ› è°ƒè¯•

### æŸ¥çœ‹è¯¦ç»†æ—¥å¿—

åœ¨ `application.properties` ä¸­å¯ç”¨debugæ—¥å¿—ï¼š

```properties
logging.level.com.aiinterview.service.OpenAiService=DEBUG
logging.level.com.aiinterview.service.PromptService=DEBUG
```

### å¸¸è§é—®é¢˜

1. **API Keyæœªé…ç½®**
   - é”™è¯¯ï¼š`OpenAI API key not configured`
   - è§£å†³ï¼šè®¾ç½® `OPENAI_API_KEY` ç¯å¢ƒå˜é‡

2. **è¯·æ±‚è¶…æ—¶**
   - é”™è¯¯ï¼š`TimeoutException`
   - è§£å†³ï¼šæ£€æŸ¥ç½‘ç»œè¿æ¥ï¼Œè€ƒè™‘å¢åŠ è¶…æ—¶æ—¶é—´

3. **Tokené™åˆ¶**
   - é”™è¯¯ï¼š`context_length_exceeded`
   - è§£å†³ï¼šå‡å°‘ `openai.max-history-messages` æˆ– `openai.max-tokens`

## ğŸ’° æˆæœ¬ä¼°ç®—

ä½¿ç”¨ GPT-3.5-turbo çš„å¤§è‡´æˆæœ¬ï¼š

- é—®é¢˜ç”Ÿæˆï¼š~500 tokens/æ¬¡ â‰ˆ $0.001
- å›ç­”è¯„ä¼°ï¼š~800 tokens/æ¬¡ â‰ˆ $0.0016
- å®Œæ•´é¢è¯•ï¼ˆ10è½®ï¼‰ï¼š~$0.026

ä½¿ç”¨ GPT-4 ä¼šè´µçº¦15å€ï¼Œä½†è´¨é‡æ›´é«˜ã€‚

## ğŸ” å®‰å…¨å»ºè®®

1. **ä¸è¦åœ¨ä»£ç ä¸­ç¡¬ç¼–ç API Key**
2. **ä½¿ç”¨ç¯å¢ƒå˜é‡æˆ–å¯†é’¥ç®¡ç†æœåŠ¡**
3. **å®ç°è¯·æ±‚é¢‘ç‡é™åˆ¶**
4. **ç›‘æ§APIä½¿ç”¨é‡å’Œæˆæœ¬**
5. **åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ä½¿ç”¨HTTPS**

## ğŸ“š æ›´å¤šèµ„æº

- [OpenAI APIæ–‡æ¡£](https://platform.openai.com/docs)
- [Spring WebFluxæ–‡æ¡£](https://docs.spring.io/spring-framework/docs/current/reference/html/web-reactive.html)
- [Reactor Project](https://projectreactor.io/)

